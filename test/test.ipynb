{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de14072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312c2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.00001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56909c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = string.ascii_lowercase + string.digits + \".\"\n",
    "char2idx = {c: i + 1 for i, c in enumerate(ALPHABET)}  # padding=0\n",
    "idx2char = {i: c for c, i in char2idx.items()}  # Reverse mapping index -> character\n",
    "vocab_size = len(char2idx) + 1\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "\n",
    "def domain_to_tensor(domain):\n",
    "    arr = [char2idx.get(c, 0) for c in domain.lower()][:MAX_LEN]\n",
    "    arr += [0] * (MAX_LEN - len(arr))\n",
    "    return torch.tensor(arr, dtype=torch.long)\n",
    "\n",
    "\n",
    "def tensor_to_domain(tensor):\n",
    "    domain = \"\".join(idx2char.get(idx, \"\") for idx in tensor.tolist() if idx > 0)  # Ignore padding (0)\n",
    "    return domain\n",
    "\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        dataloader = pickle.load(file)\n",
    "    print(f\"DataLoader loaded from {file_path}.\")\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class DomainDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dom, lbl = self.samples[idx]\n",
    "        x = domain_to_tensor(dom)\n",
    "        return x, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a06ad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_test.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_test.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(data) ) \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(data) )\n",
      "File \u001b[0;32m~/miniconda3/envs/tqf/lib/python3.10/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tqf/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_test.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_pickle('/home/dung/Downloads/Model/test/domain2/benign_test.pkl')\n",
    "print(dir(data) ) \n",
    "print(type(data) )\n",
    "print(len(data))\n",
    "\n",
    "obj = data \n",
    "print(type(obj.samples))\n",
    "print(len(obj.samples))\n",
    "\n",
    "# xem 5 phần tử đầu tiên\n",
    "for i in range(5):\n",
    "    print(\"\\n--- sample\", i, \"---\")\n",
    "    print(obj.samples[i])\n",
    "    print(\"type:\", type(obj.samples[i]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(obj.samples))\n",
    "print(len(obj.samples))\n",
    "\n",
    "# xem 5 phần tử đầu tiên\n",
    "for i in range(5):\n",
    "    print(\"\\n--- sample\", i, \"---\")\n",
    "    print(obj.samples[i])\n",
    "    print(\"type:\", type(obj.samples[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_size, embed_dim=32, hidden_dim=64, num_classes=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.bilstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        bilstm_out, _ = self.bilstm(emb)  # (batch_size, seq_len, hidden_dim*2)\n",
    "\n",
    "        # Attention Mechanism\n",
    "        attn_weights = F.softmax(self.attention(bilstm_out).squeeze(2), dim=1)  # (batch_size, seq_len)\n",
    "        attn_output = torch.bmm(attn_weights.unsqueeze(1), bilstm_out).squeeze(1)  # (batch_size, hidden_dim*2)\n",
    "\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        logits = self.fc(attn_output)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f6f915",
   "metadata": {},
   "outputs": [],
   "source": [
    "    benign_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_train.pkl\")\n",
    "    benign_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_test.pkl\")\n",
    "    dga_1_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_1_train.pkl\")\n",
    "    dga_1_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_1_test.pkl\")\n",
    "    dga_2_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_2_train.pkl\")\n",
    "    dga_2_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_2_test.pkl\")\n",
    "    dga_3_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_3_train.pkl\")\n",
    "    dga_3_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_3_test.pkl\")\n",
    "    dga_4_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_4_train.pkl\")\n",
    "    dga_4_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_4_test.pkl\")\n",
    "\n",
    "    train_ds = ConcatDataset([benign_train_ds, dga_1_train_ds, dga_2_train_ds, dga_3_train_ds, dga_4_train_ds])\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_ds = ConcatDataset([benign_test_ds, dga_1_test_ds, dga_2_test_ds, dga_3_test_ds, dga_4_test_ds])\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = BiLSTMClassifier().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef3fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_client(model, client_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for x_batch, y_batch in tqdm(client_loader):\n",
    "        if x_batch.size(0) == 1:\n",
    "            continue\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            logits = model(x_batch)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_labels.extend(y_batch.cpu().numpy().flatten())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    return f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695b1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_epochs):\n",
    "        train_client(model, train_loader, criterion, optimizer)\n",
    "        result = test_model(model, test_loader)\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716b3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
