{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de14072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312c2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.00001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56909c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = string.ascii_lowercase + string.digits + \".\"\n",
    "char2idx = {c: i + 1 for i, c in enumerate(ALPHABET)}  # padding=0\n",
    "idx2char = {i: c for c, i in char2idx.items()}  # Reverse mapping index -> character\n",
    "vocab_size = len(char2idx) + 1\n",
    "\n",
    "MAX_LEN = 50\n",
    "\n",
    "\n",
    "def domain_to_tensor(domain):\n",
    "    arr = [char2idx.get(c, 0) for c in domain.lower()][:MAX_LEN]\n",
    "    arr += [0] * (MAX_LEN - len(arr))\n",
    "    return torch.tensor(arr, dtype=torch.long)\n",
    "\n",
    "\n",
    "def tensor_to_domain(tensor):\n",
    "    domain = \"\".join(idx2char.get(idx, \"\") for idx in tensor.tolist() if idx > 0)  # Ignore padding (0)\n",
    "    return domain\n",
    "\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        dataloader = pickle.load(file)\n",
    "    print(f\"DataLoader loaded from {file_path}.\")\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class DomainDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dom, lbl = self.samples[idx]\n",
    "        x = domain_to_tensor(dom)\n",
    "        return x, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a06ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__add__', '__annotations__', '__class__', '__class_getitem__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__orig_bases__', '__parameters__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_is_protocol', 'samples']\n",
      "<class '__main__.DomainDataset'>\n",
      "200000\n",
      "<class 'list'>\n",
      "200000\n",
      "\n",
      "--- sample 0 ---\n",
      "('callcontroller.swce-02.ic3-calling-callcontroller.swedencentral-prod.cosmic.office.net', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 1 ---\n",
      "('a407.d.akamai.net', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 2 ---\n",
      "('n4i6g1.akamai.net', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 3 ---\n",
      "('mxb-0005f601.gslb.pphosted.com', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 4 ---\n",
      "('log-upload.mihoyo.com', 0)\n",
      "type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_pickle('/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_test.pkl')\n",
    "print(dir(data) ) \n",
    "print(type(data) )\n",
    "print(len(data))\n",
    "\n",
    "obj = data \n",
    "print(type(obj.samples))\n",
    "print(len(obj.samples))\n",
    "\n",
    "# xem 5 phần tử đầu tiên\n",
    "for i in range(5):\n",
    "    print(\"\\n--- sample\", i, \"---\")\n",
    "    print(obj.samples[i])\n",
    "    print(\"type:\", type(obj.samples[i]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d54f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "200000\n",
      "\n",
      "--- sample 0 ---\n",
      "('callcontroller.swce-02.ic3-calling-callcontroller.swedencentral-prod.cosmic.office.net', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 1 ---\n",
      "('a407.d.akamai.net', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 2 ---\n",
      "('n4i6g1.akamai.net', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 3 ---\n",
      "('mxb-0005f601.gslb.pphosted.com', 0)\n",
      "type: <class 'tuple'>\n",
      "\n",
      "--- sample 4 ---\n",
      "('log-upload.mihoyo.com', 0)\n",
      "type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(obj.samples))\n",
    "print(len(obj.samples))\n",
    "\n",
    "# xem 5 phần tử đầu tiên\n",
    "for i in range(5):\n",
    "    print(\"\\n--- sample\", i, \"---\")\n",
    "    print(obj.samples[i])\n",
    "    print(\"type:\", type(obj.samples[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e17d49fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size=vocab_size, embed_dim=32, hidden_dim=64, num_classes=2, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.bilstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)  # (batch_size, seq_len, embed_dim)\n",
    "        bilstm_out, _ = self.bilstm(emb)  # (batch_size, seq_len, hidden_dim*2)\n",
    "\n",
    "        # Attention Mechanism\n",
    "        attn_weights = F.softmax(self.attention(bilstm_out).squeeze(2), dim=1)  # (batch_size, seq_len)\n",
    "        attn_output = torch.bmm(attn_weights.unsqueeze(1), bilstm_out).squeeze(1)  # (batch_size, hidden_dim*2)\n",
    "\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        logits = self.fc(attn_output)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4391b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f6f915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_train.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_test.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_1_train.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_1_test.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_2_train.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_2_test.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_3_train.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_3_test.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_4_train.pkl.\n",
      "DataLoader loaded from /home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_4_test.pkl.\n"
     ]
    }
   ],
   "source": [
    "    benign_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_train.pkl\")\n",
    "    benign_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/benign_test.pkl\")\n",
    "    dga_1_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_1_train.pkl\")\n",
    "    dga_1_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_1_test.pkl\")\n",
    "    dga_2_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_2_train.pkl\")\n",
    "    dga_2_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_2_test.pkl\")\n",
    "    dga_3_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_3_train.pkl\")\n",
    "    dga_3_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_3_test.pkl\")\n",
    "    dga_4_train_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_4_train.pkl\")\n",
    "    dga_4_test_ds = load_dataset(\"/home/dung/Downloads/test-20251120T153114Z-1-001/test/domain2/dga_4_test.pkl\")\n",
    "\n",
    "    train_ds = ConcatDataset([benign_train_ds, dga_1_train_ds, dga_2_train_ds, dga_3_train_ds, dga_4_train_ds])\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    test_ds = ConcatDataset([benign_test_ds, dga_1_test_ds, dga_2_test_ds, dga_3_test_ds, dga_4_test_ds])\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = BiLSTMClassifier().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef3fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def train_client(model, client_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    for x_batch, y_batch in tqdm(client_loader):\n",
    "        if x_batch.size(0) == 1:\n",
    "            continue\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            logits = model(x_batch)\n",
    "            preds = logits.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy().flatten())\n",
    "            all_labels.extend(y_batch.cpu().numpy().flatten())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    return f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e695b1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:56<00:00, 426.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8061, Precision: 0.7822, Recall: 0.8447, F1-score: 0.8122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:51<00:00, 445.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8793, Precision: 0.8525, Recall: 0.9152, F1-score: 0.8828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:55<00:00, 429.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9025, Precision: 0.8662, Recall: 0.9505, F1-score: 0.9064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [02:01<00:00, 408.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9134, Precision: 0.8859, Recall: 0.9478, F1-score: 0.9158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:45<00:00, 472.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9190, Precision: 0.8779, Recall: 0.9721, F1-score: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:51<00:00, 445.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9263, Precision: 0.8927, Recall: 0.9678, F1-score: 0.9287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:53<00:00, 438.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9312, Precision: 0.9016, Recall: 0.9670, F1-score: 0.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:56<00:00, 424.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9325, Precision: 0.8992, Recall: 0.9731, F1-score: 0.9347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [01:53<00:00, 436.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9364, Precision: 0.9084, Recall: 0.9698, F1-score: 0.9381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49660/49660 [02:02<00:00, 406.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9401, Precision: 0.9222, Recall: 0.9604, F1-score: 0.9409\n"
     ]
    }
   ],
   "source": [
    "for _ in range(num_epochs):\n",
    "        train_client(model, train_loader, criterion, optimizer)\n",
    "        result = test_model(model, test_loader)\n",
    "        print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716b3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tqf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
